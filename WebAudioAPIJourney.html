<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css">
</head>

<body>


    <div class="container">
        <div class="row py-5">
            <canvas id="chart" style="border-radius: 2px;width:100%; height:200px"></canvas>
        </div>
    </div>
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"></script>
    <script src="https://cdn.bootcss.com/smoothie/1.34.0/smoothie.js"></script>
    <script>
        // Create a time series
        var series = new TimeSeries();

        // init the canvas with the time series
        (function (series, canvas) {
            let chart = new SmoothieChart({
                millisPerPixel:30,
                responsive: true,
                enableDpiScaling: false,
                scrollBackwards: true,
            });

            chart.addTimeSeries(series, {strokeStyle: 'rgba(0, 255, 0, 1)'});            
            chart.streamTo(canvas);
        })(series, $('#chart')[0]);

        function isIOS() {
            return /iphone|ipad/i.test(navigator.userAgent);
        }

        var constraints = {
            audio: true
        };

        navigator.mediaDevices.getUserMedia(constraints).then(stream => {
            console.log(`get ${ JSON.stringify(constraints) } ok`);

            let audioCtx = new(window.AudioContext || window.webkitAudioContext)();
            if (isIOS()) {
                // https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/Using_HTML5_Audio_Video/PlayingandSynthesizingSounds/PlayingandSynthesizingSounds.html
                // Note: On iOS, the Web Audio API requires sounds to be triggered from an explicit user action, such as a tap.
                // so first suspend the audio content, and then add a event listener
                audioCtx.suspend().then(function () {
                    console.log("init suspended when ios");
                });

                document.addEventListener('touchend', function () {
                    if (this.state === 'running') {} else {
                        this.resume().then(() => console.log("resume"));
                    }
                }.bind(audioCtx));
            }

            // define the audio routing graph
            let source = audioCtx.createMediaStreamSource(stream);
            let scriptNode = audioCtx.createScriptProcessor(0, 1, 1);
            source.connect(scriptNode);
            scriptNode.connect(audioCtx.destination);

            scriptNode.onaudioprocess = audioProcessingEvent => {
                let factor = 1;
                let inputData = audioProcessingEvent.inputBuffer.getChannelData(0);
                let v = inputData.reduce((a, b) => {
                    return a + b
                });

                v = Math.round(v * factor);
                series.append(Date.now(), v);
            };
        }).catch(err => {
            console.log(err);
        });
    </script>
</body>

</html>